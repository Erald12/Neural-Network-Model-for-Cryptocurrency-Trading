import ccxt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from datetime import datetime, timedelta
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ReduceLROnPlateau
from sklearn.preprocessing import MinMaxScaler
import talib


import keras
from tensorflow.keras.models import load_model


# Initialize Bitget exchange
exchange = ccxt.bitget({
    'apiKey': 'bg_e10bcb723a9a90953160094bf0177465',
    'secret': 'fc8bb8253252b1caf6c22077c656b82027076290d669cee8c746f57e44975ac5',
    'password': 'Easy09159562534',
})


# Define the trading pair and timeframe
symbol = 'BNB/USDT'
timeframe = '5m'

# Fetch historical data from Bitget
limit = 864  # Number of candles to retrieve
hours_diff = 72

# Calculate the start time as 12 hours ago from the current time
today_time = datetime.now()
past_time1 = today_time - timedelta(hours=hours_diff)
past_time2 = past_time1 - timedelta(hours=hours_diff)
past_time3 = past_time2 - timedelta(hours=hours_diff)
past_time4 = past_time3 - timedelta(hours=hours_diff)
past_time5 = past_time4 - timedelta(hours=hours_diff)
past_time6 = past_time5 - timedelta(hours=hours_diff)
past_time7 = past_time6 - timedelta(hours=hours_diff)
past_time8 = past_time7 - timedelta(hours=hours_diff)
past_time9 = past_time8 - timedelta(hours=hours_diff)
past_time10 = past_time9 - timedelta(hours=hours_diff)
past_time11 = past_time10 - timedelta(hours=hours_diff)
past_time12 = past_time11 - timedelta(hours=hours_diff)
past_time13 = past_time12 - timedelta(hours=hours_diff)
past_time14 = past_time13 - timedelta(hours=hours_diff)
past_time15 = past_time14 - timedelta(hours=hours_diff)
past_time16 = past_time15 - timedelta(hours=hours_diff)
past_time17 = past_time16 - timedelta(hours=hours_diff)
past_time18 = past_time17 - timedelta(hours=hours_diff)
past_time19 = past_time18 - timedelta(hours=hours_diff)
past_time20 = past_time19 - timedelta(hours=hours_diff)
past_time21 = past_time20 - timedelta(hours=hours_diff)
past_time22 = past_time21 - timedelta(hours=hours_diff)
past_time23 = past_time22 - timedelta(hours=hours_diff)
past_time24 = past_time23 - timedelta(hours=hours_diff)
past_time25 = past_time24 - timedelta(hours=hours_diff)
past_time26 = past_time25 - timedelta(hours=hours_diff)

# Convert start_time and end_time to Unix timestamps (milliseconds since epoch)
past1_timestamp = int(past_time1.timestamp()) * 1000
past2_timestamp = int(past_time2.timestamp()) * 1000
past3_timestamp = int(past_time3.timestamp()) * 1000
past4_timestamp = int(past_time4.timestamp()) * 1000
past5_timestamp = int(past_time5.timestamp()) * 1000
past6_timestamp = int(past_time6.timestamp()) * 1000
past7_timestamp = int(past_time7.timestamp()) * 1000
past8_timestamp = int(past_time8.timestamp()) * 1000
past9_timestamp = int(past_time9.timestamp()) * 1000
past10_timestamp = int(past_time10.timestamp()) * 1000
past11_timestamp = int(past_time11.timestamp()) * 1000
past12_timestamp = int(past_time12.timestamp()) * 1000
past13_timestamp = int(past_time13.timestamp()) * 1000
past14_timestamp = int(past_time14.timestamp()) * 1000
past15_timestamp = int(past_time15.timestamp()) * 1000
past16_timestamp = int(past_time16.timestamp()) * 1000
past17_timestamp = int(past_time17.timestamp()) * 1000
past18_timestamp = int(past_time18.timestamp()) * 1000
past19_timestamp = int(past_time19.timestamp()) * 1000
past20_timestamp = int(past_time20.timestamp()) * 1000
past21_timestamp = int(past_time21.timestamp()) * 1000
past22_timestamp = int(past_time22.timestamp()) * 1000
past23_timestamp = int(past_time23.timestamp()) * 1000
past24_timestamp = int(past_time24.timestamp()) * 1000
past25_timestamp = int(past_time25.timestamp()) * 1000
past26_timestamp = int(past_time26.timestamp()) * 1000


#Fetching Data Sets
ohlcv_past1 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit, since=past1_timestamp)
ohlcv_past2 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past2_timestamp)
ohlcv_past3 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past3_timestamp)
ohlcv_past4 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past4_timestamp)
ohlcv_past5 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past5_timestamp)
ohlcv_past6 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past6_timestamp)
ohlcv_past7 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past7_timestamp)
ohlcv_past8 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past8_timestamp)
ohlcv_past9 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past9_timestamp)
ohlcv_past10 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past10_timestamp)
ohlcv_past11 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past11_timestamp)
ohlcv_past12 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past12_timestamp)
ohlcv_past13 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past13_timestamp)
ohlcv_past14 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past14_timestamp)
ohlcv_past15 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past15_timestamp)
ohlcv_past16 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past16_timestamp)
ohlcv_past17 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past17_timestamp)
ohlcv_past18 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past18_timestamp)
ohlcv_past19 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past19_timestamp)
ohlcv_past20 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past20_timestamp)
ohlcv_past21 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past21_timestamp)
ohlcv_past22 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past22_timestamp)
ohlcv_past23 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past23_timestamp)
ohlcv_past24 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past24_timestamp)
ohlcv_past25 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past25_timestamp)
ohlcv_past26 = exchange.fetch_ohlcv(symbol, timeframe, limit=limit-1, since=past26_timestamp)

# Combine historical data
ohlcv = ohlcv_past1 + ohlcv_past2 + ohlcv_past3 + ohlcv_past4 + ohlcv_past5 + ohlcv_past6 + ohlcv_past7 + ohlcv_past8 + ohlcv_past9 + ohlcv_past10 + ohlcv_past11 + ohlcv_past12 + ohlcv_past13 + ohlcv_past14 + ohlcv_past15 + ohlcv_past16 + ohlcv_past17 + ohlcv_past18 + ohlcv_past19 + ohlcv_past20 + ohlcv_past21 + ohlcv_past22 + ohlcv_past23 + ohlcv_past24 + ohlcv_past25 + ohlcv_past26

# Sort the combined data by timestamp in ascending order
ohlcv.sort(key=lambda x: x[0])  # Assuming the timestamp is in the first column (index 0) of each OHLCV data point

df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])


# Define a function to calculate RSI
def calculate_rsi(prices, period=14):
    rsi = talib.RSI(prices, timeperiod=period)
    return rsi

def calculate_ema9(data):
    ema9 = talib.EMA(data, timeperiod=4)
    return ema9

def calculate_SMA30(data):
    ema9 = talib.SMA(data, timeperiod=30)
    return ema9

# Data preprocessing
# Extract the 'close' prices
prices_close = df['close'].values
prices_close_list = list(df['close'].values)


rsi14 = calculate_rsi(prices_close)
# Check for NaN values
mask_rsi = np.isnan(rsi14)
rsi14 = rsi14[~mask_rsi]

print(np.prod(prices_close.shape))
ema9 = calculate_ema9(rsi14)

ema9_close = calculate_SMA30(prices_close)

# Check for NaN values
mask = np.isnan(ema9)
ema = ema9[~mask]

mask_close = np.isnan(ema9_close)
ema9_close = ema9_close[~mask_close]
print(np.prod(ema.shape))

# Calculate differences (i.e., subtract each value from the previous one)
price_diff = np.diff(ema)

# Reshape the data if necessary
ema = ema.reshape(-1, 1)
ema9_close = ema9_close.reshape(-1, 1)

# Optionally, you can also apply Robust scaling after log transformation
scaler = MinMaxScaler()
ema = scaler.fit_transform(ema)

scaler2 = MinMaxScaler()
ema9_close = scaler2.fit_transform(ema9_close)

# Split data into training and testing sets
train_size = int(len(ema) * 0.975)
train_data, test_data = ema[0:train_size], ema[train_size:]

train_size_close = int(len(ema9_close) * 0.975)
train_data_close, test_data_close = ema9_close[0:train_size_close], ema9_close[train_size_close:]

# Create sequences for training
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

seq_length = 40  # Experiment with different sequence lengths
X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)


seq_length2 = 40
X_train_close, y_train_close = create_sequences(train_data_close, seq_length2)
X_test_close, y_test_close = create_sequences(test_data_close, seq_length2)

# Define the EarlyStopping callback
early_stopping = EarlyStopping(
    monitor='loss',  # Quantity to monitor (validation loss in this case)
    patience=3,          # Number of epochs with no improvement after which training will be stopped
    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity
)

reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2, min_lr=0.0001)

# Build the CNN model
cnn_filters = 32
cnn_kernel_size = 10

model_rsi = load_model('5min_model1_RSI.h5')
model_close = load_model('5min_model1_Price.h5')

# Make predictions on the test set
y_pred = model_rsi.predict(X_test)
model_rsi.fit(
    X_train,  # Input data for training
    y_train,  # Target data for training
    epochs=150,  # Number of training epochs
    batch_size=64,  # Batch size
    callbacks=[early_stopping, reduce_lr]  # Optional callbacks
)
# Save the trained model to a file
model_rsi.save('5min_model1_RSI.h5')

# Inverse transform the predictions to the original scale
y_pred = scaler.inverse_transform(y_pred)
y_test = scaler.inverse_transform(y_test)

# Calculate the root mean squared error
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error:", rmse)

# Make forecasts on future data
# Adjust the forecast_length to 20
forecast_length = 20
future_data = ema[-seq_length:]
forecast = []

# Make forecasts on future data
for i in range(forecast_length):
    # Prepare the input for prediction
    input_data = future_data[-seq_length:].reshape(1, seq_length, 1)

    # Predict the next price point based on the input data
    next_price = model_rsi.predict(input_data)

    # Append the predicted price to the forecast
    forecast.append(next_price[0, 0])

    # Update the future_data for the next iteration
    future_data = np.append(future_data, next_price)

# Inverse transform the forecasted ema to the original scale
forecast = scaler.inverse_transform(np.array(forecast).reshape(-1, 1))

# Calculate lower and upper bounds for the confidence interval
confidence_interval = 1.96  # Adjust this value based on your desired confidence level
lower_bound = forecast - confidence_interval * rmse
upper_bound = forecast + confidence_interval * rmse




###################################################################################
y_pred_close = model_close.predict(X_test_close)
model_close.fit(
    X_train_close,  # Input data for training
    y_train_close,  # Target data for training
    epochs=150,  # Number of training epochs
    batch_size=64,  # Batch size
    callbacks=[early_stopping, reduce_lr]  # Optional callbacks
)
# Save the trained model to a file
model_close.save('5min_model1_Price.h5')

# Inverse transform the predictions to the original scale
y_pred_close = scaler2.inverse_transform(y_pred_close)
y_test_close = scaler2.inverse_transform(y_test_close)

# Calculate the root mean squared error
rmse_close = np.sqrt(mean_squared_error(y_test_close, y_pred_close))
print("Root Mean Squared Error:", rmse_close)

# Make forecasts on future data
# Adjust the forecast_length to 30
forecast_length2 = 20
future_data_close = ema9_close[-seq_length2:]
forecast_close = []

# Make forecasts on future data
for i in range(forecast_length2):
    # Prepare the input for prediction
    input_data = future_data_close[-seq_length2:].reshape(1, seq_length2, 1)

    # Predict the next price point based on the input data
    next_price = model_close.predict(input_data)

    # Append the predicted price to the forecast
    forecast_close.append(next_price[0, 0])

    # Update the future_data for the next iteration
    future_data_close = np.append(future_data_close, next_price)

# Inverse transform the forecasted ema to the original scale
forecast_close = scaler2.inverse_transform(np.array(forecast_close).reshape(-1, 1))

# Calculate lower and upper bounds for the confidence interval
confidence_interval = 1.96  # Adjust this value based on your desired confidence level
lower_bound_close = forecast_close - confidence_interval * rmse_close
upper_bound_close = forecast_close + confidence_interval * rmse_close

test_data_price = prices_close[-len(y_test):]



# Visualize the observed, predicted, and forecasted ema with the confidence interval
plt.figure(figsize=(12, 6))
plt.subplot(2, 1, 1)
plt.plot(np.arange(len(y_test)), y_test, label='Observed EMA4_RSI', color='blue')
plt.plot(np.arange(len(y_test)), y_pred, label='Predicted EMA4_RSI', color='red')
plt.plot(np.arange(len(y_test), len(y_test) + forecast_length2), forecast, label='Forecasted EMA4_RSI', color='green')
plt.fill_between(np.arange(len(y_test), len(y_test) + forecast_length2), lower_bound.flatten(), upper_bound.flatten(), alpha=0.2, color='green', label='Confidence Interval')
plt.xlabel('Time')
plt.ylabel(f'{symbol} EMA4_RSI')
plt.title(f'{symbol} {timeframe} EMA4_RSI Prediction and Forecast with Confidence Interval')
plt.legend()
#plt.savefig('ema_rsi_forecast_plot.png')


# Visualize the observed, predicted, and forecasted ema with the confidence interval
plt.subplot(2, 1, 2)
plt.plot(np.arange(len(y_test_close)), y_test_close, label='Observed SMA30_Close_Price', color='blue')
plt.plot(np.arange(len(test_data_price)), test_data_price, label='Observed Price', color='black')
plt.plot(np.arange(len(y_test_close)), y_pred_close, label='Predicted SMA30_Price', color='red')
plt.plot(np.arange(len(y_test_close), len(y_test_close) + forecast_length2), forecast_close, label='Forecasted SMA30_Price', color='green')
plt.fill_between(np.arange(len(y_test_close), len(y_test_close) + forecast_length2), lower_bound_close.flatten(), upper_bound_close.flatten(), alpha=0.2, color='green', label='Confidence Interval')
plt.xlabel('Time')
plt.ylabel(f'{symbol} SMA30_Close_Price')
plt.title(f'{symbol} {timeframe} SMA30_Close_Price Prediction and Forecast with Confidence Interval')
plt.legend()
#plt.savefig('ema_close_forecast_plot.png')


plt.tight_layout()

plt.savefig('combined_forecast_plot.png')





